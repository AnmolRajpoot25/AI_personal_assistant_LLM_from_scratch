{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 7.2 preparing a dataset for supervised instruction finetuning",
   "id": "a87c55e3b107a809"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:13.906179Z",
     "start_time": "2025-12-16T10:23:13.845644Z"
    }
   },
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import urllib\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:14.388461Z",
     "start_time": "2025-12-16T10:23:14.363463Z"
    }
   },
   "cell_type": "code",
   "source": "data[50]",
   "id": "66aa5592ba77cc8e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Identify the correct spelling of the following word.',\n",
       " 'input': 'Ocassion',\n",
       " 'output': \"The correct spelling is 'Occasion.'\"}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:15.056442Z",
     "start_time": "2025-12-16T10:23:15.048440Z"
    }
   },
   "cell_type": "code",
   "source": "data[999]",
   "id": "4f24d305a0d21efb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': \"What is an antonym of 'complicated'?\",\n",
       " 'input': '',\n",
       " 'output': \"An antonym of 'complicated' is 'simple'.\"}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:15.370049Z",
     "start_time": "2025-12-16T10:23:15.342277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_input(entry ):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "\n",
    "    )\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else\"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ],
   "id": "451266928aaf48b8",
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:15.946822Z",
     "start_time": "2025-12-16T10:23:15.929379Z"
    }
   },
   "cell_type": "code",
   "source": "print(format_input(data[999]))",
   "id": "48cc25d0a3bd4e7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:16.400225Z",
     "start_time": "2025-12-16T10:23:16.387226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n\\n### response:\\n{data[999]['output']}\"\n",
    "print (model_input+ desired_response)"
   ],
   "id": "184f8c6155c1b082",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "\n",
      "### response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:16.604664Z",
     "start_time": "2025-12-16T10:23:16.582565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_portion = int(len(data) *0.85)\n",
    "test_portion = int(len(data) *0.1)\n",
    "val_portion = len(data) -test_portion- train_portion\n",
    "\n",
    "train_data= data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n"
   ],
   "id": "ecd1804f5baac5ef",
   "outputs": [],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:16.760008Z",
     "start_time": "2025-12-16T10:23:16.753993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ],
   "id": "850fcffde92b39c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 7.3 organizing dataset into training dataset",
   "id": "b711b0673fc3ad5c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:17.105077Z",
     "start_time": "2025-12-16T10:23:17.081011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ],
   "id": "e5e394ecd5cf5c7b",
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:17.263539Z",
     "start_time": "2025-12-16T10:23:17.247962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ],
   "id": "8e6e521991e61e07",
   "outputs": [],
   "execution_count": 125
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:17.436030Z",
     "start_time": "2025-12-16T10:23:17.416073Z"
    }
   },
   "cell_type": "code",
   "source": "# train_loader = DataLoader(train_data, collate_fn = custom_collate...)",
   "id": "6368e033a9336f2a",
   "outputs": [],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:17.592392Z",
     "start_time": "2025-12-16T10:23:17.583184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def custom_collate_draft_1(\n",
    "        batch ,\n",
    "        pad_token_id = 50256,\n",
    "        device = \"cpu\"\n",
    "):\n",
    "\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    input_lst =[]\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item  + [pad_token_id]*\n",
    "            (batch_max_length -len(new_item))\n",
    "        )\n",
    "        inputs =torch.tensor(padded[:-1])\n",
    "        input_lst.append(inputs)\n",
    "\n",
    "\n",
    "    inputs_tensor = torch.stack(input_lst).to(device)\n",
    "    return inputs_tensor"
   ],
   "id": "e62deba8b61471cf",
   "outputs": [],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:17.858701Z",
     "start_time": "2025-12-16T10:23:17.778205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_draft_1(batch))"
   ],
   "id": "38b36e755b1c7b48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:18.234392Z",
     "start_time": "2025-12-16T10:23:18.222876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def custom_collate_draft_2(\n",
    "        batch,\n",
    "        pad_token_id = 50256,\n",
    "        device = \"cpu\"\n",
    "):\n",
    "\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    inputs_lst, targets_lst =[] , []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item  + [pad_token_id]*\n",
    "            (batch_max_length -len(new_item))\n",
    "        )\n",
    "        inputs =torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor , targets_tensor"
   ],
   "id": "a2140488cee93549",
   "outputs": [],
   "execution_count": 129
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:18.738610Z",
     "start_time": "2025-12-16T10:23:18.726600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "inputs_tensor , targets_tensor = custom_collate_draft_2(batch)"
   ],
   "id": "8e6023e89c71ae24",
   "outputs": [],
   "execution_count": 130
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:19.193900Z",
     "start_time": "2025-12-16T10:23:19.173907Z"
    }
   },
   "cell_type": "code",
   "source": "inputs_tensor",
   "id": "9fbf756bcda656a0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     1,     2,     3,     4],\n",
       "        [    5,     6, 50256, 50256, 50256],\n",
       "        [    7,     8,     9, 50256, 50256]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:19.572974Z",
     "start_time": "2025-12-16T10:23:19.558251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def custom_collate_fn(\n",
    "        batch,\n",
    "        pad_token_id = 50256,\n",
    "        ignore_index = -100,\n",
    "        allowed_max_length = None ,\n",
    "        device = \"cpu\"\n",
    "):\n",
    "\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    inputs_lst, targets_lst =[] , []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item  + [pad_token_id]*\n",
    "            (batch_max_length -len(new_item))\n",
    "        )\n",
    "        inputs =torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor , targets_tensor"
   ],
   "id": "7742a1d7751577e4",
   "outputs": [],
   "execution_count": 132
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:19.996582Z",
     "start_time": "2025-12-16T10:23:19.960048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "inputs_tensor , targets_tensor = custom_collate_fn(batch)"
   ],
   "id": "e9e5a723e11836af",
   "outputs": [],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:20.391476Z",
     "start_time": "2025-12-16T10:23:20.378418Z"
    }
   },
   "cell_type": "code",
   "source": "inputs_tensor",
   "id": "5878e21354b73c9a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     1,     2,     3,     4],\n",
       "        [    5,     6, 50256, 50256, 50256],\n",
       "        [    7,     8,     9, 50256, 50256]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:20.786617Z",
     "start_time": "2025-12-16T10:23:20.767663Z"
    }
   },
   "cell_type": "code",
   "source": "targets_tensor",
   "id": "705fa0bab0b45549",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,     2,     3,     4, 50256],\n",
       "        [    6, 50256,  -100,  -100,  -100],\n",
       "        [    8,     9, 50256,  -100,  -100]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:21.189091Z",
     "start_time": "2025-12-16T10:23:21.138519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],  # 1st training example\n",
    "     [-0.5, 1.5]]  # 2nd training example\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "\n",
    "\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ],
   "id": "d1a96b3305787754",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:21.690020Z",
     "start_time": "2025-12-16T10:23:21.658736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]  # New 3rd training example\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ],
   "id": "b8efb67da7f856e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:22.064089Z",
     "start_time": "2025-12-16T10:23:22.050506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "# print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ],
   "id": "663e774cbbbe360c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "execution_count": 138
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 7.4 Creating data loaders for an instruction dataset",
   "id": "3fc492902f10c085"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:22.490712Z",
     "start_time": "2025-12-16T10:23:22.478084Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
   "id": "d41a8d9d8dd5822a",
   "outputs": [],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:22.944442Z",
     "start_time": "2025-12-16T10:23:22.921397Z"
    }
   },
   "cell_type": "code",
   "source": "device",
   "id": "13548d780fc827ef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 140
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:24.022746Z",
     "start_time": "2025-12-16T10:23:24.014776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device = device ,\n",
    "    allowed_max_length = 1024\n",
    ")"
   ],
   "id": "bcf84739bec6910",
   "outputs": [],
   "execution_count": 141
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:24.584550Z",
     "start_time": "2025-12-16T10:23:24.439167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "nums_worker =0\n",
    "batch_size =8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle = True,\n",
    "    drop_last = True,\n",
    "    num_workers=nums_worker\n",
    "    )\n"
   ],
   "id": "db029842270abd0d",
   "outputs": [],
   "execution_count": 142
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:25.194195Z",
     "start_time": "2025-12-16T10:23:25.159993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle = False,\n",
    "    drop_last = False,\n",
    "    num_workers=nums_worker\n",
    "    )\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle = False,\n",
    "    drop_last = False,\n",
    "    num_workers=nums_worker\n",
    "    )\n",
    "\n"
   ],
   "id": "b03fdec7115ad6b7",
   "outputs": [],
   "execution_count": 143
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:26.041084Z",
     "start_time": "2025-12-16T10:23:25.602631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ],
   "id": "393b12f6c7352c7a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "execution_count": 144
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:26.275629Z",
     "start_time": "2025-12-16T10:23:26.257621Z"
    }
   },
   "cell_type": "code",
   "source": "print(inputs[0])",
   "id": "61bb862f409e9a34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n",
      "          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:26.852321Z",
     "start_time": "2025-12-16T10:23:26.835218Z"
    }
   },
   "cell_type": "code",
   "source": "print(targets[0])",
   "id": "5e64a7f9772f7558",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
      "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
      "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 146
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 7.5 Loading a pretrained LLM",
   "id": "d7d4bb912ad8561b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:54.049647Z",
     "start_time": "2025-12-16T10:23:27.993167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": True\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();\n"
   ],
   "id": "48df51d583dadd32",
   "outputs": [],
   "execution_count": 147
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:23:54.095712Z",
     "start_time": "2025-12-16T10:23:54.062621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ],
   "id": "80763cb5e7f4e6f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "execution_count": 148
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:36:37.838684Z",
     "start_time": "2025-12-16T10:36:22.370679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from previous_chapters import (\n",
    "    generate,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ],
   "id": "9a4977929e5fa7f8",
   "outputs": [],
   "execution_count": 159
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:37:18.706130Z",
     "start_time": "2025-12-16T10:37:18.694953Z"
    }
   },
   "cell_type": "code",
   "source": "print(generated_text)",
   "id": "a183683cb09324f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Response:\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "execution_count": 160
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:40:07.470557Z",
     "start_time": "2025-12-16T10:40:07.458023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response_text = (\n",
    "    generated_text[len(input_text):]\n",
    "    .replace(\"### Response:\" , \"\")\n",
    "    .strip()\n",
    ")\n",
    "print(response_text)"
   ],
   "id": "f1ed4b2c6c218a10",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "execution_count": 162
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 7.6 Finetuning the LLM on instruction data",
   "id": "3b6d97038e63193a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:40:41.920202Z",
     "start_time": "2025-12-16T10:40:41.915928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from previous_chapters import (\n",
    "    calc_loss_loader,\n",
    "    train_model_simple\n",
    ")"
   ],
   "id": "cb61612f297630c2",
   "outputs": [],
   "execution_count": 163
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T10:42:34.805617Z",
     "start_time": "2025-12-16T10:42:31.450816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ],
   "id": "fe87bfbe99f8d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.825909423828125\n",
      "Validation loss: 3.761933994293213\n"
     ]
    }
   ],
   "execution_count": 164
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T11:19:39.713935Z",
     "start_time": "2025-12-16T10:45:27.893802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ],
   "id": "19587b0b87c37d67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
      "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.103\n",
      "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.944\n",
      "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
      "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
      "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
      "Ep 1 (Step 000030): Train loss 0.799, Val loss 0.836\n",
      "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.808\n",
      "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
      "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.789\n",
      "Ep 1 (Step 000050): Train loss 0.663, Val loss 0.783\n",
      "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.763\n",
      "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
      "Ep 1 (Step 000065): Train loss 0.653, Val loss 0.735\n",
      "Ep 1 (Step 000070): Train loss 0.534, Val loss 0.730\n",
      "Ep 1 (Step 000075): Train loss 0.567, Val loss 0.731\n",
      "Ep 1 (Step 000080): Train loss 0.602, Val loss 0.727\n",
      "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.712\n",
      "Ep 1 (Step 000090): Train loss 0.566, Val loss 0.694\n",
      "Ep 1 (Step 000095): Train loss 0.502, Val loss 0.685\n",
      "Ep 1 (Step 000100): Train loss 0.505, Val loss 0.681\n",
      "Ep 1 (Step 000105): Train loss 0.568, Val loss 0.673\n",
      "Ep 1 (Step 000110): Train loss 0.559, Val loss 0.668\n",
      "Ep 1 (Step 000115): Train loss 0.514, Val loss 0.664\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Ep 2 (Step 000120): Train loss 0.436, Val loss 0.671\n",
      "Ep 2 (Step 000125): Train loss 0.453, Val loss 0.686\n",
      "Ep 2 (Step 000130): Train loss 0.447, Val loss 0.682\n",
      "Ep 2 (Step 000135): Train loss 0.406, Val loss 0.679\n",
      "Ep 2 (Step 000140): Train loss 0.408, Val loss 0.678\n",
      "Ep 2 (Step 000145): Train loss 0.372, Val loss 0.679\n",
      "Ep 2 (Step 000150): Train loss 0.381, Val loss 0.675\n",
      "Ep 2 (Step 000155): Train loss 0.414, Val loss 0.676\n",
      "Ep 2 (Step 000160): Train loss 0.413, Val loss 0.686\n",
      "Ep 2 (Step 000165): Train loss 0.379, Val loss 0.689\n",
      "Ep 2 (Step 000170): Train loss 0.324, Val loss 0.680\n",
      "Ep 2 (Step 000175): Train loss 0.337, Val loss 0.666\n",
      "Ep 2 (Step 000180): Train loss 0.392, Val loss 0.654\n",
      "Ep 2 (Step 000185): Train loss 0.418, Val loss 0.657\n",
      "Ep 2 (Step 000190): Train loss 0.340, Val loss 0.648\n",
      "Ep 2 (Step 000195): Train loss 0.328, Val loss 0.635\n",
      "Ep 2 (Step 000200): Train loss 0.310, Val loss 0.633\n",
      "Ep 2 (Step 000205): Train loss 0.353, Val loss 0.628\n",
      "Ep 2 (Step 000210): Train loss 0.362, Val loss 0.628\n",
      "Ep 2 (Step 000215): Train loss 0.392, Val loss 0.636\n",
      "Ep 2 (Step 000220): Train loss 0.296, Val loss 0.644\n",
      "Ep 2 (Step 000225): Train loss 0.338, Val loss 0.656\n",
      "Ep 2 (Step 000230): Train loss 0.291, Val loss 0.654\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
      "Training completed in 34.20 minutes.\n"
     ]
    }
   ],
   "execution_count": 165
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T11:37:49.720583Z",
     "start_time": "2025-12-16T11:37:49.576816Z"
    }
   },
   "cell_type": "code",
   "source": "from previous_chapters import plot_losses",
   "id": "da4c5da7abd8613d",
   "outputs": [],
   "execution_count": 166
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T11:37:55.188509Z",
     "start_time": "2025-12-16T11:37:53.763738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ],
   "id": "a51cee0fcd4dd2d8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 167
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 7.7 extracting and saving response",
   "id": "e6718f59adee1849"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T11:48:32.303804Z",
     "start_time": "2025-12-16T11:48:28.900257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ],
   "id": "c1880b5c03ccaa33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a bullet.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud typically associated with thunderstorms is a cumulus cloud.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "execution_count": 168
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T11:58:10.601304Z",
     "start_time": "2025-12-16T11:53:52.366153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "for i , entry in tqdm(enumerate(test_data), total= len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)\n"
   ],
   "id": "6adf9a62c359e62b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 110/110 [04:18<00:00,  2.35s/it]\n"
     ]
    }
   ],
   "execution_count": 169
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T11:58:10.693394Z",
     "start_time": "2025-12-16T11:58:10.656730Z"
    }
   },
   "cell_type": "code",
   "source": "test_data[0]\n",
   "id": "f18b4c128001bb78",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Rewrite the sentence using a simile.',\n",
       " 'input': 'The car is very fast.',\n",
       " 'output': 'The car is as fast as lightning.',\n",
       " 'model_response': 'The car is as fast as a bullet.'}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 170
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "len(test_data)",
   "id": "5f0dd0a56db5c69e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T12:00:08.087692Z",
     "start_time": "2025-12-16T11:59:58.703242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL)}-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")\n",
    "\n",
    "\n"
   ],
   "id": "d969595468204368",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "execution_count": 171
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 7.8 EVALUATING LLMs",
   "id": "2f2da2bec79cf2c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T12:37:00.637528Z",
     "start_time": "2025-12-16T12:37:00.597447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import psutil\n",
    "\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ],
   "id": "94000f7b4abba935",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T12:37:10.621335Z",
     "start_time": "2025-12-16T12:37:10.586133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "file_path = \"instruction-data-with-response.json\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    test_data = json.load(file)\n",
    "\n",
    "\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ],
   "id": "36b0d57a8b2140f4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T12:55:09.494179Z",
     "start_time": "2025-12-16T12:54:58.056900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests  # noqa: F811\n",
    "import json\n",
    "# import urllib.request\n",
    "\n",
    "def query_model(\n",
    "    prompt,\n",
    "    model=\"llama3.2:latest\",\n",
    "    # If you used OLLAMA_HOST=127.0.0.1:11435 ollama serve\n",
    "    # update the address from 11434 to 11435\n",
    "    url=\"http://localhost:11434/api/chat\"\n",
    "):\n",
    "    # Create the data payload as a dictionary\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"options\": {     # Settings below are required for deterministic responses\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Send the POST request\n",
    "    with requests.post(url, json=data, stream=True, timeout=30) as r:\n",
    "        r.raise_for_status()\n",
    "        response_data = \"\"\n",
    "        for line in r.iter_lines(decode_unicode=True):\n",
    "            if not line:\n",
    "                continue\n",
    "            response_json = json.loads(line)\n",
    "            if \"message\" in response_json:\n",
    "                response_data += response_json[\"message\"][\"content\"]\n",
    "\n",
    "    return response_data\n",
    "\n",
    "\n",
    "model = \"llama3.2:latest\"\n",
    "result = query_model(\"What do Llamas eat?\", model)\n",
    "print(result);\n"
   ],
   "id": "26ec39fcbb41421f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are herbivores, which means they primarily eat plants and plant-based foods. Their diet typically consists of:\n",
      "\n",
      "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and grassy weeds.\n",
      "2. Hay: High-quality hay, such as timothy hay or alfalfa hay, is a staple in a llama's diet.\n",
      "3. Grains: Llamas may also be fed grains like oats, barley, or corn, but these should not make up more than 10% of their diet.\n",
      "4. Fruits and vegetables: Fresh fruits and vegetables, such as apples, carrots, and sweet potatoes, can be given to llamas as treats or added to their hay.\n",
      "5. Browse: Llamas may also eat browse, which includes leaves, twigs, and other vegetation from trees and shrubs.\n",
      "\n",
      "It's essential to note that llamas have a unique digestive system, with a three-part stomach and a large cecum (a specialized part of the large intestine). This allows them to break down and extract nutrients from plant material more efficiently than many other animals. As a result, their diet should be high in fiber and low in protein.\n",
      "\n",
      "A balanced llama diet typically includes:\n",
      "\n",
      "* 70-80% hay\n",
      "* 10-20% grains\n",
      "* 5-10% fruits and vegetables\n",
      "\n",
      "It's always best to consult with a veterinarian or experienced llama breeder to determine the specific dietary needs of your llama.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T12:55:33.446580Z",
     "start_time": "2025-12-16T12:55:15.059020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "for entry in test_data[:3]:\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and correct output `{entry['output']}`, \"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "    )\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", query_model(prompt))\n",
    "    print(\"\\n-------------------------\")"
   ],
   "id": "d0e6b1594160d6ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a bullet.\n",
      "\n",
      "Score:\n",
      ">> To rewrite the sentence using a simile, we need to compare the speed of the car to something else.\n",
      "\n",
      "Correct output: The car is as fast as lightning.\n",
      "\n",
      "Score: 100\n",
      "\n",
      "The model response \"The car is as fast as a bullet\" is close, but not perfect. A simile should use \"like\" or \"as\" to make the comparison, whereas \"as fast as a bullet\" implies that the car is literally a bullet, which isn't the intended meaning.\n",
      "\n",
      "A better score for the model response would be around 80-90, as it's close to the correct form but not quite there.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud typically associated with thunderstorms is a cumulus cloud.\n",
      "\n",
      "Score:\n",
      ">> I would rate the model response a 0 out of 100.\n",
      "\n",
      "The correct answer is \"cumulonimbus\", not \"cumulus\". Cumulus clouds are typically associated with fair weather and are often seen on warm, sunny days. They are characterized by their puffy, white appearance and are usually low-level clouds.\n",
      "\n",
      "Cumulonimbus clouds, on the other hand, are tall, dense clouds that can reach heights of over 10,000 meters (33,000 feet). They are associated with thunderstorms, heavy rain, and even tornadoes. The name \"cumulonimbus\" comes from the Latin words \"cumulus\", meaning \"heap\" or \"pile\", and \"nimbus\", meaning \"cloud\".\n",
      "\n",
      "Therefore, the model response is incorrect and would result in a score of 0 out of 100.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "Score:\n",
      ">> ### Input\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "### Output\n",
      "Jane Austen.\n",
      "\n",
      "### Score: 100/100\n",
      "\n",
      "The response is complete, accurate, and concise, making it a perfect score. The sentence structure is correct, and the information provided is relevant to the question asked.\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T13:18:18.049649Z",
     "start_time": "2025-12-16T13:13:19.147639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_model_scores(json_data, json_key, model=\"llama3.2:latest\"):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model output `{entry[json_key]}` on a scale of 1 to 100. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except:\n",
    "            continue\n",
    "    return scores\n",
    "\n",
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")\n"
   ],
   "id": "91b8deaec86b74fa",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|| 110/110 [04:58<00:00,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 96 of 110\n",
      "Average score: 549.17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3563bab62a836d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
